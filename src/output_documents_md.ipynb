{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import re\n",
    "import pandas as pd\n",
    "from lib.utils import BASE_DIR,DATA_DIR,OUTPUT_DIR,get_full_outcomes\n",
    "from lib.dataframe_to_text import dataframe_to_text\n",
    "\n",
    "data_path = os.path.join(DATA_DIR,\"documents\")\n",
    "def get_target_competencies(target:str)->list[str]:\n",
    "    filename = os.path.join(data_path,target,\"meta.yaml\")\n",
    "    if not os.path.isfile(filename):\n",
    "        return []\n",
    "    with open(filename, 'r') as yml:\n",
    "        config = yaml.safe_load(yml)\n",
    "    if config == None:\n",
    "        return []\n",
    "    competencies = config.get(\"competencies\",[])\n",
    "    return competencies\n",
    "\n",
    "def load_competencies_for_uid():\n",
    "    l1 = pd.read_csv(os.path.join(DATA_DIR,\"outcomes_l1.csv\")).rename(columns={\"index\":\"l1_index\"})\n",
    "    l2 = pd.read_csv(os.path.join(DATA_DIR,\"outcomes_l2.csv\")).rename(columns={\"index\":\"l2_index\"})\n",
    "    l3 = pd.read_csv(os.path.join(DATA_DIR,\"outcomes_l3.csv\")).rename(columns={\"index\":\"l3_index\"})\n",
    "    l4 = pd.read_csv(os.path.join(DATA_DIR,\"outcomes_l4.csv\")).rename(columns={\"index\":\"l4_index\"})\n",
    "    l2 = pd.merge(l1.rename(columns={\"UID\":\"l1_UID\"}),l2,on=\"l1_index\")\n",
    "    l3 = pd.merge(l2.rename(columns={\"UID\":\"l2_UID\"}),l3,on=\"l2_index\")\n",
    "    l4 = pd.merge(l3.rename(columns={\"UID\":\"l3_UID\"}),l4,on=\"l3_index\")\n",
    "    l1 = l1.rename(columns={\"l1_index\":\"index\"})\n",
    "    l2 = l2.rename(columns={\"l2_index\":\"index\"})\n",
    "    l3 = l3.rename(columns={\"l3_index\":\"index\"})\n",
    "    l4 = l4.rename(columns={\"l4_index\":\"index\"})\n",
    "    united = pd.concat([l1,l2,l3,l4]).fillna(\"\")\n",
    "    united[\"order\"] = united.reset_index().index\n",
    "    return united.set_index(\"UID\")\n",
    "\n",
    "competencies_for_uid = load_competencies_for_uid()\n",
    "def select_target_competencies_row(target:str):\n",
    "    competencies = get_target_competencies(target)\n",
    "    if len(competencies)==0:\n",
    "        return pd.DataFrame([])\n",
    "    competencies = list(set(competencies) & set(competencies_for_uid.index))\n",
    "    result = competencies_for_uid\\\n",
    "        .loc[competencies,:]\n",
    "    result = result\\\n",
    "        .sort_values(\"order\")\\\n",
    "        .loc[:,[\"l1\",\"l2\",\"l3\",\"l4\"]]\n",
    "    result[\"l2\"] = \"    \"+result[\"l2\"]\n",
    "    result[\"l3\"] = \"        \"+result[\"l3\"]\n",
    "    result[\"l4\"] = \"            \"+result[\"l4\"]\n",
    "    return result\n",
    "\n",
    "def get_target_competencies_text(target:str):\n",
    "    df = select_target_competencies_row(target)\n",
    "    if df.empty:\n",
    "        return \"\"\n",
    "    text = dataframe_to_text(df)\n",
    "    text = re.sub(r\"^\\s*\\n\",\"\",text,flags=re.MULTILINE)\n",
    "    text = re.sub(r\"^(\\s*)(.+)\",r\"\\1- \\2\",text,flags=re.MULTILINE)\n",
    "    return text\n",
    "\n",
    "#get_target_competencies(\"case_PR\")\n",
    "#select_target_competencies_row(\"case_PR\")\n",
    "#print(get_target_competencies_text(\"case_PR\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import path\n",
    "import re\n",
    "import os\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import textwrap\n",
    "from lib.utils import BASE_DIR,DATA_DIR,OUTPUT_DIR,get_full_outcomes\n",
    "from collections.abc import Callable\n",
    "\n",
    "\n",
    "def load_markdown(filename:str):\n",
    "    with open(filename) as f:\n",
    "        text = f.read()\n",
    "    return text\n",
    "\n",
    "def add_title_level(markdown_text:str,level_to_add:int):\n",
    "    prefix = \"#\" * level_to_add\n",
    "    return re.sub(r\"^(#+) \",prefix+r\"\\1 \",markdown_text, flags=re.MULTILINE)\n",
    "\n",
    "def replace_image_path(markdown_text:str,replace_func:Callable[[str],str])->str:\n",
    "    def match_fn(match):\n",
    "        new_path = replace_func(match.group(2))\n",
    "        return f\"![{match.group(1)}]({new_path})\"\n",
    "    return re.sub(r\"!\\[(.*?)\\] *\\((.+?)\\)\",match_fn,markdown_text )\n",
    "\n",
    "\n",
    "os.makedirs(OUTPUT_DIR,exist_ok=True)\n",
    "\n",
    "data_path = path.join(DATA_DIR,\"documents\")\n",
    "dirs = [f for f in os.listdir(data_path) if not os.path.isfile(os.path.join(data_path, f))] \n",
    "for dir in dirs:\n",
    "    shutil.copytree(os.path.join(data_path, dir),os.path.join(OUTPUT_DIR,dir),dirs_exist_ok=True)\n",
    "\n",
    "\n",
    "document_index = pd.read_csv(path.join(DATA_DIR,\"documents_index.csv\"))\n",
    "document_index\n",
    "\n",
    "output_dict = {}\n",
    "for item in document_index.itertuples():\n",
    "    filename = path.join(DATA_DIR,\"documents\",item.filename+\".md\")\n",
    "    text = load_markdown(filename)\n",
    "    text = add_title_level(text,1)\n",
    "    title = \"\\n\\n# \"+item.title +\"\\n\\n\"\n",
    "    competencies = get_target_competencies_text(item.filename)\n",
    "    if not competencies==\"\":\n",
    "        competencies = \"\\n## 学修する資質・能力\\n\\n\"+competencies+\"\\n\\n\"\n",
    "    text = competencies+text\n",
    "    prev = output_dict.get(item.section,\"\")\n",
    "    if prev:\n",
    "        prev = prev + \"\\n\\\\newpage\"\n",
    "    output_dict[item.section] = prev+\"\\n\\n\"+title+text\n",
    "\n",
    "bundle = \"\"\n",
    "for key,item in output_dict.items():\n",
    "    sections = list(key.split(\"/\"))\n",
    "    item = add_title_level(item,len(sections))\n",
    "    title = \"#\" * len(sections) +\" \"+sections[-1]+\"\\n\\n\"\n",
    "    bundle += \"\\n\\\\newpage\\n\" + title + competencies+item +\"\\n\\n\"\n",
    "\n",
    "bundle = replace_image_path(bundle,lambda p: os.path.join(\"output\",p))\n",
    "\n",
    "with open(path.join(OUTPUT_DIR,\"bundle_documents.md\"),\"w\") as f:\n",
    "    f.write(bundle)\n",
    "\n",
    "def replace_boxed_paragraph(markdown_text:str)->str:\n",
    "    before_start = r\"^:::* \\{ *\\.note *\\}\"\n",
    "    before_end = r\"^:::*\"\n",
    "    before = f\"{before_start}(.+?){before_end}\"\n",
    "    def match_fn(match:re.Match):\n",
    "        text = match.group(1)\n",
    "        text = text.replace(\"<br>\",\"\\\\\\n\\n\")\n",
    "        after_start = \"\\n\\n\"+\"-\"*60+\"\\n\"\n",
    "        after_end = \"\\n\"+\"-\"*60+\"\\n\\n\"\n",
    "        result = after_start+text.strip()+after_end\n",
    "        print(result)\n",
    "        return result\n",
    "    return re.sub(before,match_fn,markdown_text,flags=(re.MULTILINE | re.DOTALL))\n",
    "\n",
    "documents_for_tex = bundle\n",
    "documents_for_tex = replace_boxed_paragraph(documents_for_tex)\n",
    "with open(path.join(OUTPUT_DIR,\"documents_for_tex.md\"),\"w\") as f:\n",
    "    f.write(documents_for_tex)\n",
    "\n",
    "with open(path.join(OUTPUT_DIR,\"documents_for_docx.md\"),\"w\") as f:\n",
    "    f.write(bundle)\n",
    "\n",
    "\n",
    "output_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "949777d72b0d2535278d3dc13498b2535136f6dfe0678499012e853ee9abcab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
